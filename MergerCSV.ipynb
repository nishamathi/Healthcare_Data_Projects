{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "with open('../Allowable/Allowable_2017/Allowable_2017.csv', 'a') as singleFile:\n",
    "    for csv in glob('../Allowable/Allowable_2017/*.csv'):\n",
    "        if csv == 'main.csv':\n",
    "            pass\n",
    "        else:\n",
    "            for line in open(csv, 'r'):\n",
    "                singleFile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "with open('../Allowable/Allowable_2018/Allowable_2018.csv', 'a') as singleFile:\n",
    "    for csv in glob('../Allowable/Allowable_2018/*.csv'):\n",
    "        if csv == 'main.csv':\n",
    "            pass\n",
    "        else:\n",
    "            for line in open(csv, 'r'):\n",
    "                singleFile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages/libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path to the data directory into which the cleaned data is saved.\n",
    "csv_file_path = os.path.join(\"..\", \"Allowable\",\"Allowable_2018\",\"Q1_2018.csv\")\n",
    "#csv_file_path_1 = os.path.join(\"..\", \"EOC_Raw_Data\", \"EOC_Data_2018.csv\")\n",
    "if not os.path.exists(csv_file_path):\n",
    "    print(\"{} doesn't exist - perhaps the data cleaning script needs to be run?\".format(csv_file_path))\n",
    "\n",
    "# set option to display all columns in a dataframe \n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into dataframe\n",
    "df1 = pd.read_csv(csv_file_path, quoting=2, parse_dates=True, infer_datetime_format=True, encoding=\"UTF-8\",low_memory=False, skiprows=1,index_col=0,error_bad_lines = False)\n",
    "#df_2018 = pd.read_csv(csv_file_path_1, quoting=2, parse_dates=True, infer_datetime_format=True, encoding=\"UTF-8\",low_memory=False)\n",
    "\n",
    "# display first 5 rows in the dataframe\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data directory into which the cleaned data is saved.\n",
    "csv_file_path = os.path.join(\"..\", \"Allowable\",\"Allowable_2018\",\"Q2_2018.csv\")\n",
    "#csv_file_path_1 = os.path.join(\"..\", \"EOC_Raw_Data\", \"EOC_Data_2018.csv\")\n",
    "if not os.path.exists(csv_file_path):\n",
    "    print(\"{} doesn't exist - perhaps the data cleaning script needs to be run?\".format(csv_file_path))\n",
    "    # read data into dataframe\n",
    "df2 = pd.read_csv(csv_file_path, quoting=2, parse_dates=True, infer_datetime_format=True, encoding=\"UTF-8\",low_memory=False,index_col=0,error_bad_lines = False)\n",
    "#df_2018 = pd.read_csv(csv_file_path_1, quoting=2, parse_dates=True, infer_datetime_format=True, encoding=\"UTF-8\",low_memory=False)\n",
    "\n",
    "# display first 5 rows in the dataframe\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data directory into which the cleaned data is saved.\n",
    "csv_file_path = os.path.join(\"..\", \"Allowable\",\"Allowable_2018\",\"Q3_2018.csv\")\n",
    "#csv_file_path_1 = os.path.join(\"..\", \"EOC_Raw_Data\", \"EOC_Data_2018.csv\")\n",
    "if not os.path.exists(csv_file_path):\n",
    "    print(\"{} doesn't exist - perhaps the data cleaning script needs to be run?\".format(csv_file_path))\n",
    "    # read data into dataframe\n",
    "df3 = pd.read_csv(csv_file_path, quoting=2, parse_dates=True, infer_datetime_format=True, encoding=\"UTF-8\",low_memory=False, skiprows=1,index_col=0,error_bad_lines = False)\n",
    "#df_2018 = pd.read_csv(csv_file_path_1, quoting=2, parse_dates=True, infer_datetime_format=True, encoding=\"UTF-8\",low_memory=False)\n",
    "\n",
    "# display first 5 rows in the dataframe\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data directory into which the cleaned data is saved.\n",
    "csv_file_path = os.path.join(\"..\", \"Allowable\",\"Allowable_2018\",\"Q4_2018.csv\")\n",
    "#csv_file_path_1 = os.path.join(\"..\", \"EOC_Raw_Data\", \"EOC_Data_2018.csv\")\n",
    "if not os.path.exists(csv_file_path):\n",
    "    print(\"{} doesn't exist - perhaps the data cleaning script needs to be run?\".format(csv_file_path))\n",
    "    # read data into dataframe\n",
    "df4 = pd.read_csv(csv_file_path, quoting=2, parse_dates=True, infer_datetime_format=True, encoding=\"UTF-8\",low_memory=False, skiprows=1,index_col=0,error_bad_lines = False)\n",
    "#df_2018 = pd.read_csv(csv_file_path_1, quoting=2, parse_dates=True, infer_datetime_format=True, encoding=\"UTF-8\",low_memory=False)\n",
    "\n",
    "# display first 5 rows in the dataframe\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_1 = df2.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_4 = df4.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2_1.append(df3_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Allowable/Allowable_2018/Allowable_2018.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
